% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download-file.R
\name{download_file}
\alias{download_file}
\title{Download an S3 object to a file}
\usage{
download_file(bucket, key, filename, extra_args = NULL,
  transfer_config = list(multipart_threshold = 8388608L, max_concurrency =
  10L, multipart_chunksize = 8388608L, num_download_attempts = 5L, max_io_queue
  = 100L, io_chunksize = 262144L, use_threads = TRUE),
  aws_access_key_id = NULL, aws_secret_access_key = NULL,
  aws_session_token = NULL, region_name = NULL, profile_name = NULL)
}
\arguments{
\item{bucket}{name of the bucket to download from.}

\item{key}{name of the key to download from.}

\item{filename}{path to the file to download to.}

\item{extra_args}{arguments that may be passed to the client operation.}

\item{transfer_config}{transfer configuration to be used when performing the transfer.
Pre-defined, default values are provided for the following settings:
\itemize{
\item \code{multipart_threshold}: The transfer size threshold for which multipart uploads,
downloads, and copies will automatically be triggered.
\item \code{max_concurrency}: The maximum number of threads that will be making requests
to perform a transfer. If use_threads is set to False, the value provided is
ignored as the transfer will only ever use the main thread.
\item \code{multipart_chunksize}: The partition size of each part for a multipart transfer.
\item \code{num_download_attempts}: The number of download attempts that will be retried
upon errors with downloading an object in S3. Note that these retries account
for errors that occur when streaming down the data from s3 (i.e. socket errors
and read timeouts that occur after recieving an OK response from s3). Other
retryable exceptions such as throttling errors and 5xx errors are already
retried by botocore (this default is 5). This does not take into account the
number of exceptions retried by botocore.
\item \code{max_io_queue}: The maximum amount of read parts that can be queued in memory
to be written for a download. The size of each of these read parts is at most
the size of io_chunksize.
\item \code{io_chunksize}: The max size of each chunk in the io queue. Currently, this
is size used when read is called on the downloaded stream as well.
\item \code{use_threads}: If \code{TRUE}, threads will be used when performing S3 transfers.
If \code{FALSE}, no threads will be used in performing transfers: all logic will
be ran in the main thread.
}}

\item{aws_access_key_id}{AWS access key id}

\item{aws_secret_access_key}{AWS secret access key}

\item{aws_session_token}{AWS session token}

\item{region_name}{region name}

\item{profile_name}{profile name}
}
\description{
Download an S3 object to a file
}
\examples{
\dontrun{
download_file("mybucket", "hello.txt", "/tmp/hello.txt")
}
}
\references{
\url{https://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.download_file}
}
